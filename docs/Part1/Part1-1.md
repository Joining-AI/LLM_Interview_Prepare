## 什么是大模型：
"大模型"（Large Model）在人工智能和机器学习领域通常指的是参数数量非常庞大的深度学习模型。这些模型通常具备以下几个特点：

1. **参数数量庞大**：大模型拥有数十亿甚至数万亿的参数。
2. **数据量巨大**：为了训练大模型，需要海量的数据。
3. **计算资源需求高**：训练和部署大模型需要非常强大的计算资源。
4. **强大的泛化能力**：大模型通常具备很强的泛化能力，能够在各种任务上表现出色。
5. **自监督学习**：很多大模型采用自监督学习方法，从大量未标注数据中学习特征。
6. **涌现能力**：涌现（英语：emergence）或称创发、突现、呈展、演生，是一种现象，为许多小实体相互作用后产生了大实体，而这个大实体展现了组成它的小实体所不具有的特性。引申到模型层面，涌现能力指的是当模型的训练数据突破一定规模，模型突然涌现出之前小模型所没有的、意料之外的、能够综合分析和解决更深层次问题的复杂能力和特性，展现出类似人类的思维和智能。涌现能力也是大模型最显著的特点之一。
7. **应用广泛**：大模型在实际应用中有广泛的应用场景。

一般来讲，大模型所直接指代的是自然语言处理的模型，但严格意义上来讲，其正确的名称应为大语言模型，其代表包括：OpenAI 的 GPT 系列、Google 的 BERT、Transformer 模型、DeepMind 的 AlphaFold 等。
考虑以上定义，一般的参数量较大的模型也可一般归类为“大模型”，一般标准为10B。以这样的衡量标准，包括Stable Diffusion在内的模型（例如，Sd v3 的最大模型参数量已经达到8B规模）已经摸到了所谓“大模型”的门槛，因而也可以被归为此类。

[返回](index.md)